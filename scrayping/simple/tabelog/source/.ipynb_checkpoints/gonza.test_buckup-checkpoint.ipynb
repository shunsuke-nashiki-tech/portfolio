{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib, requests, regex, csv, re, math, time, datetime, random\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################\n",
    "#パラメータ・変数を定義する\n",
    "####################################\n",
    "\n",
    "#スクレイピング後の待機時間\n",
    "wait_time = random.randint(5, 10)\n",
    "\n",
    "#県名\n",
    "prefectures = \"東京都\"\n",
    "\n",
    "#市名\n",
    "city_name = \"銀座\"\n",
    "\n",
    "#取得対象URL\n",
    "target_get_url = \"https://tabelog.com/tokyo/A1301/A130101/\"\n",
    "\n",
    "#実行日\n",
    "run_time = str(datetime.date.today())\n",
    "\n",
    "#CSVファイル名\n",
    "csv_file_name = \"../csv/tabelog\" + \"_\" + prefectures + \"_\" + city_name + \"_\" + run_time + \".csv\"\n",
    "\n",
    "#ページ数の初期値\n",
    "page_number = 1\n",
    "\n",
    "#取得失敗後の待機時間\n",
    "error_after_wait_time = 60\n",
    "\n",
    "#取得成功\n",
    "success_after_wait_time = random.randint(5, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#格納用CSVを生成\n",
    "def create_list():\n",
    "\n",
    "    #グローバル変数を生成\n",
    "    global detail_url_list #詳細URL\n",
    "    global shop_name_list #店舗名\n",
    "    global evaluation_list #評価\n",
    "    global prefectures_list #都道府県\n",
    "    global nearest_station_list #最寄り駅\n",
    "    global street_adress_list #住所\n",
    "    global budget_ranchi_lower_list #予算_昼_下限\n",
    "    global budget_ranchi_upper_list #予算_昼_上限\n",
    "    global budget_dinner_lower_list #予算_夜_下限\n",
    "    global budget_dinner_upper_list #予算_夜_上限\n",
    "\n",
    "    #リストを生成\n",
    "    detail_url_list = []\n",
    "    shop_name_list = []\n",
    "    evaluation_list = []\n",
    "    prefectures_list = []\n",
    "    nearest_station_list = []\n",
    "    street_adress_list = []\n",
    "    budget_ranchi_lower_list = []\n",
    "    budget_ranchi_upper_list = []\n",
    "    budget_dinner_lower_list = []\n",
    "    budget_dinner_upper_list = []\n",
    "    \n",
    "    #格納されているか判定する用の配列に格納\n",
    "    global append_judge_array\n",
    "    \n",
    "    append_judge_array = [\n",
    "    company_name_list,\n",
    "    medium_name_list,\n",
    "    area_list,\n",
    "    input_date_list,\n",
    "    job_details_url_list,\n",
    "    recruitment_point_list,\n",
    "    ask_talent_list,\n",
    "    work_location_list,\n",
    "    office_list,\n",
    "    company_url_list]\n",
    "            \n",
    "#関数を実行\n",
    "create_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#要素を取得\n",
    "class Get_data:\n",
    "    \n",
    "    #BeautifulSoupを取得\n",
    "    def __init__(self,url_adress):\n",
    "        \n",
    "        self.url_adress = url_adress\n",
    "        \n",
    "        #Beautifulsoupで要素を取得\n",
    "        self.html = urllib.request.urlopen(self.url_adress)\n",
    "        self.soup = BeautifulSoup(self.html, 'lxml')\n",
    "        \n",
    "    #ページを取得\n",
    "    def get_page_count(self) ->int:\n",
    "        \n",
    "        #全件数を取得して、1ページの要素数（20件）で除算\n",
    "        for table in self.soup.findAll(class_=\"list-condition__count\"):\n",
    "            self.page_count = re.sub(\",\",\"\",table.text)\n",
    "            self.page_count = math.ceil(int(self.page_count) / 20)\n",
    "            \n",
    "        return self.page_count\n",
    "    \n",
    "    #求人詳細URLを取得\n",
    "    def get_detail_url(self,file_path) ->str:\n",
    "        \n",
    "        #CSVがなければHeaderを作成\n",
    "        try:\n",
    "            self.read_file = pd.pd.read_csv(file_path,encoding='cp932')\n",
    "        except:\n",
    "            #Headerを生成\n",
    "            detail_url_list.append(\"詳細URL\")\n",
    "        \n",
    "        for table in self.soup.findAll(class_=\"list-rst__header\"):\n",
    "            for parts in table.findAll(class_=\"list-rst__rst-name-target cpy-rst-name\"):\n",
    "                self.detail_url = parts.get(\"href\")\n",
    "                detail_url_list.append(self.detail_url)\n",
    "                \n",
    "        return self.detail_url\n",
    "    \n",
    "    #詳細URL内の各要素を取得\n",
    "    def get_elements(self,file_path) ->str:\n",
    "        \n",
    "        \n",
    "        \n",
    "        #CSVがなければHeaderを作成\n",
    "        try:\n",
    "            self.read_file = pd.pd.read_csv(file_path,encoding='cp932')\n",
    "        except:\n",
    "            shop_name_list.append(\"店舗名\")\n",
    "            evaluation_list.append(\"評価\")\n",
    "            prefectures_list.append(\"都道府県\")\n",
    "            nearest_station_list.append(\"最寄り駅\")\n",
    "            street_adress_list.append(\"住所\")\n",
    "            budget_ranchi_lower_list.append(\"予算_昼_下限\")\n",
    "            budget_ranchi_upper_list.append(\"予算_昼_上限\")\n",
    "            budget_dinner_lower_list.append(\"予算_夜_下限\")\n",
    "            budget_dinner_upper_list.append(\"予算_夜_上限\")\n",
    "        \n",
    "        #店名を取得\n",
    "        for table in self.soup.findAll(class_=\"rstinfo-table\"):\n",
    "            for shop_name_sub in table.findAll(\"tr\"):\n",
    "                for parts in shop_name_sub.findAll(\"th\"):\n",
    "                    if regex.findall(\"店名\",parts.text):\n",
    "                        self.shop_name = shop_name_sub.find(\"td\")\n",
    "                        self.shop_name = re.sub(\"\\r|\\t|\\n|\\u3000|\\xa0| \",\"\",self.shop_name.text)\n",
    "                        shop_name_list.append(self.shop_name)\n",
    "                        \n",
    "        #評価を取得\n",
    "        for table in self.soup.findAll(class_=\"rdheader-counts-wrap\"):\n",
    "            for parts in table.findAll(class_=\"rdheader-rating__score-val-dtl\"):\n",
    "                self.evaluation = re.sub(\"\\r|\\t|\\n|\\u3000|\\xa0| \",\"\",parts.text)\n",
    "                evaluation_list.append(self.evaluation)\n",
    "                \n",
    "        #都道府県を取得\n",
    "        prefectures_list.append(prefectures)\n",
    "        \n",
    "        #最寄り駅を取得\n",
    "        #for table in self.soup.findAll(id = \"location\"):\n",
    "            #for parts in table.findAll(class_=\"js-analytics\"):\n",
    "        \n",
    "        #最寄り駅を取得\n",
    "        nearest_station_list.append(city_name)\n",
    "                \n",
    "        #住所を取得\n",
    "        for table in self.soup.findAll(class_=\"rstinfo-table\"):\n",
    "            for street_address_sub in table.findAll(\"tr\"):\n",
    "                for parts in street_address_sub.findAll(\"th\"):\n",
    "                    if regex.findall(\"住所\",parts.text):\n",
    "                        self.street_address = street_address_sub.find(\"td\").find(\"p\")\n",
    "                        self.street_address = re.sub(\"\\r|\\t|\\n|\\u3000|\\xa0|\",\"\",self.street_address.text)\n",
    "                        street_adress_list.append(self.street_address)\n",
    "                        \n",
    "        #予算を取得\n",
    "        for table in self.soup.findAll(class_=\"rstinfo-table\"):\n",
    "            for budget_sub in table.findAll(\"tr\"):\n",
    "                for parts in budget_sub.findAll(\"th\"):\n",
    "                    parts = re.sub(\" \",\"\",parts.text)\n",
    "                    if parts == \"予算\":\n",
    "                        self.budget = budget_sub.find(\"td\")\n",
    "                        self.budget = re.sub(\"\\r|\\t|\\n|\\u3000|\\xa0| \",\"\",self.budget.text)\n",
    "                        \n",
    "                        #予算_昼_下限を取得\n",
    "                        self.budget_ranchi_lower = self.budget.split(\"[昼]\")[1].split(\"～\")[0]\n",
    "                        budget_ranchi_lower_list.append(self.budget_ranchi_lower)\n",
    "                        \n",
    "                        #予算_昼_上限を取得\n",
    "                        self.budget_ranchi_upper = self.budget.split(\"[昼]\")[1].split(\"～\")[1]\n",
    "                        budget_ranchi_upper_list.append(self.budget_ranchi_upper)\n",
    "                        \n",
    "                        #予算_夜_下限を取得\n",
    "                        self.budget_dinner_lower = self.budget.split(\"[夜]\")[1].split(\"～\")[0]\n",
    "                        budget_dinner_lower_list.append(self.budget_dinner_lower)\n",
    "                        \n",
    "                        #予算_夜_上限を取得\n",
    "                        self.budget_dinner_upper = self.budget.split(\"[夜]\")[1].split(\"～\")[1].split(\"[昼]\")[0]\n",
    "                        budget_dinner_lower_list.append(self.budget_dinner_upper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Create_csv(file_path):\n",
    "    \n",
    "    #データテーブルを作成\n",
    "    data = zip(detail_url_list,\n",
    "               shop_name_list,\n",
    "               evaluation_list,\n",
    "               prefectures_list,\n",
    "               nearest_station_list,\n",
    "               street_adress_list,\n",
    "               budget_ranchi_lower_list,\n",
    "               budget_ranchi_upper_list,\n",
    "               budget_dinner_lower_list,\n",
    "               budget_dinner_upper_list\n",
    "              )\n",
    "        \n",
    "    append_number = 0\n",
    "    for x in append_judge_array:\n",
    "        if len(append_judge_array[append_number]) == 0:\n",
    "            append_judge_array[append_number].append(\"null\")\n",
    "        append_number += 1\n",
    "        \n",
    "        with open(file_path,'a',errors='backslashreplace',encoding=\"SHIFT-JIS\") as fout:\n",
    "            writecsv = csv.writer(fout,lineterminator='\\n')  \n",
    "            writecsv.writerows(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_data = Get_data(\"https://tabelog.com/tokyo/A1301/A130101/13220469/\")\n",
    "get_data.get_elements(csv_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
